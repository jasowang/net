Bottom: 806b2b6d775a96b97944b13d68e7261b1c8e135b
Top:    c4ac9fdc53aaef39a11a2cc47d798872925cf6ef
Author: Jason Wang <jasowang@redhat.com>
Date:   2017-09-02 11:22:21 +0800

vhost: prefetch vring descriptors

Signed-off-by: Jason Wang <jasowang@redhat.com>


---

diff --git a/drivers/vhost/net.c b/drivers/vhost/net.c
index e610685..acca816 100644
--- a/drivers/vhost/net.c
+++ b/drivers/vhost/net.c
@@ -482,6 +482,8 @@ static void handle_tx(struct vhost_net *net)
 	}
 
 	for (;;) {
+		bool cont = false;
+
 		/* Release DMAs done buffers first */
 		if (zcopy)
 			vhost_zerocopy_signal_used(net, vq);
@@ -492,7 +494,8 @@ static void handle_tx(struct vhost_net *net)
 		if (unlikely(vhost_exceeds_maxpend(net)))
 			break;
 
-		avails = vhost_prefetch_desc_indices(vq, heads, batched);
+		avails = vhost_prefetch_desc_indices(vq, heads, vq->descs,
+						     batched, &cont);
 		/* On error, stop handling until the next kick. */
 		if (unlikely(avails < 0))
 			break;
@@ -509,10 +512,12 @@ static void handle_tx(struct vhost_net *net)
 		}
 
 		for (i = 0; i < avails; i++) {
+			struct vring_desc *d = cont ? &vq->descs[i] : NULL;
+
 			head = __vhost_get_vq_desc(vq, vq->iov,
 						   ARRAY_SIZE(vq->iov),
-						   &out, &in, NULL, NULL, NULL,
-					       vhost16_to_cpu(vq, heads[i].id));
+						   &out, &in, NULL, NULL, d,
+						   vhost16_to_cpu(vq, heads[i].id));
 			if (in) {
 				vq_err(vq, "Unexpected descriptor format for "
 					   "TX: out %d, int %d\n", out, in);
diff --git a/drivers/vhost/vhost.c b/drivers/vhost/vhost.c
index bb61859..457133c 100644
--- a/drivers/vhost/vhost.c
+++ b/drivers/vhost/vhost.c
@@ -2051,17 +2051,17 @@ int __vhost_get_vq_desc(struct vhost_virtqueue *vq,
 			struct iovec iov[], unsigned int iov_size,
 			unsigned int *out_num, unsigned int *in_num,
 			struct vhost_log *log, unsigned int *log_num,
-			struct vring_desc *descs,
+			struct vring_desc *d,
 			__virtio16 head)
 {
-	struct vring_desc *desc = descs;
-	struct vring_desc d;
-
+	struct vring_desc vring_desc, *desc = &vring_desc;
 	unsigned int i, found = 0;
 	int ret = 0, access;
 
-	if (!desc)
-		desc = &d;
+	if (!d)
+		desc = &vring_desc;
+	else
+		desc = d;
 
 	/* If their number is silly, that's an error. */
 	if (unlikely(head > vq->num)) {
@@ -2089,9 +2089,23 @@ int __vhost_get_vq_desc(struct vhost_virtqueue *vq,
 			       i, vq->num, head);
 			return -EINVAL;
 		}
+<<<<<<< current
 
 		if (!desc)
 			desc = vq->desc_vaddr + i;
+=======
+		if (!d) {
+			ret = vhost_copy_from_user(vq, desc, vq->desc + i,
+						   sizeof desc[0]);
+			if (unlikely(ret)) {
+				vq_err(vq, "Failed to get descriptor: "
+	                                   "idx %d addr %p\n",
+					i, vq->desc + i);
+				return -EFAULT;
+			}
+		} else
+			d = NULL;
+>>>>>>> patched
 		if (desc->flags & cpu_to_vhost16(vq, VRING_DESC_F_INDIRECT)) {
 			ret = get_indirect(vq, iov, iov_size,
 					   out_num, in_num,
@@ -2482,7 +2496,8 @@ EXPORT_SYMBOL_GPL(vhost_dequeue_msg);
 
 int vhost_prefetch_desc_indices(struct vhost_virtqueue *vq,
 				struct vring_used_elem *heads,
-				u16 num)
+				struct vring_desc *descs,
+				u16 num, bool *cont)
 {
 	int ret, ret2;
 	u16 last_avail_idx, last_used_idx, total, copied;
@@ -2498,10 +2513,13 @@ int vhost_prefetch_desc_indices(struct vhost_virtqueue *vq,
 		}
 		vq->avail_idx = vhost16_to_cpu(vq, avail_idx);
 	}
+
 	last_avail_idx = vq->last_avail_idx & (vq->num - 1);
 	total = vq->avail_idx - vq->last_avail_idx;
 	ret = total = min(total, num);
 
+	*cont = true;
+
 	for (i = 0; i < ret; i++) {
 		ret2 = vhost_get_avail(vq, heads[i].id,
 				      &vq->avail->ring[last_avail_idx]);
@@ -2510,6 +2528,10 @@ int vhost_prefetch_desc_indices(struct vhost_virtqueue *vq,
 			return -EFAULT;
 		}
 		last_avail_idx = (last_avail_idx + 1) & (vq->num - 1);
+		if (i > 0 && *cont && heads[i].id !=
+			((heads[i - 1].id + 1) & (vq->num - 1))) {
+			*cont = false;
+		}
 	}
 
 	last_used_idx = vq->last_used_idx & (vq->num - 1);
@@ -2529,6 +2551,25 @@ int vhost_prefetch_desc_indices(struct vhost_virtqueue *vq,
 		total -= copied;
 	}
 
+
+	if (*cont) {
+		total = ret;
+		while (total) {
+			int i = ret - total;
+			__virtio16 ring_head = vhost16_to_cpu(vq, heads[i].id);
+
+			copied = min((u16)(vq->num - ring_head), total);
+			ret2 = vhost_copy_from_user(vq, &descs[i],
+					    vq->desc + ring_head,
+					    copied * sizeof descs[0]);
+			if (unlikely(ret2)) {
+				vq_err(vq, "Failed to get descriptor\n");
+				return -EFAULT;
+			}
+			total -= copied;
+		}
+	}
+
 	/* Only get avail ring entries after they have been exposed by guest. */
 	smp_rmb();
 	return ret;
diff --git a/drivers/vhost/vhost.c.rej b/drivers/vhost/vhost.c.rej
new file mode 100644
index 0000000..a33ff11
--- /dev/null
+++ b/drivers/vhost/vhost.c.rej
@@ -0,0 +1,65 @@
+--- drivers/vhost/vhost.c
++++ drivers/vhost/vhost.c
+@@ -290,6 +290,7 @@ static void vhost_vq_reset(struct vhost_dev *dev,
+ 	vq->avail = NULL;
+ 	vq->used = NULL;
+ 	vq->last_avail_idx = 0;
++	vq->last_used_event = 0;
+ 	vq->avail_idx = 0;
+ 	vq->last_used_idx = 0;
+ 	vq->signalled_used = 0;
+@@ -1324,7 +1325,7 @@ long vhost_vring_ioctl(struct vhost_dev *d, int ioctl, void __user *argp)
+ 			r = -EINVAL;
+ 			break;
+ 		}
+-		vq->last_avail_idx = s.num;
++		vq->last_avail_idx = vq->last_used_event = s.num;
+ 		/* Forget the cached index value. */
+ 		vq->avail_idx = vq->last_avail_idx;
+ 		break;
+@@ -2159,10 +2160,6 @@ static bool vhost_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
+ 	__u16 old, new;
+ 	__virtio16 event;
+ 	bool v;
+-	/* Flush out used index updates. This is paired
+-	 * with the barrier that the Guest executes when enabling
+-	 * interrupts. */
+-	smp_mb();
+ 
+ 	if (vhost_has_feature(vq, VIRTIO_F_NOTIFY_ON_EMPTY) &&
+ 	    unlikely(vq->avail_idx == vq->last_avail_idx))
+@@ -2170,6 +2167,10 @@ static bool vhost_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
+ 
+ 	if (!vhost_has_feature(vq, VIRTIO_RING_F_EVENT_IDX)) {
+ 		__virtio16 flags;
++		/* Flush out used index updates. This is paired
++		 * with the barrier that the Guest executes when enabling
++		 * interrupts. */
++		smp_mb();
+ 		if (vhost_get_user(vq, flags, &vq->avail->flags)) {
+ 			vq_err(vq, "Failed to get flags");
+ 			return true;
+@@ -2184,11 +2185,22 @@ static bool vhost_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
+ 	if (unlikely(!v))
+ 		return true;
+ 
++	if (vring_need_event(vq->last_used_event, new + vq->num, new) &&
++	    !vring_need_event(vq->last_used_event, new, old))
++		return false;
++
++	/* Flush out used index updates. This is paired
++	 * with the barrier that the Guest executes when enabling
++	 * interrupts. */
++	smp_mb();
++
+ 	if (vhost_get_user(vq, event, vhost_used_event(vq))) {
+ 		vq_err(vq, "Failed to get used event idx");
+ 		return true;
+ 	}
+-	return vring_need_event(vhost16_to_cpu(vq, event), new, old);
++	vq->last_used_event = vhost16_to_cpu(vq, event);
++
++	return vring_need_event(vq->last_used_event, new, old);
+ }
+ 
+ /* This actually signals the guest, using eventfd. */
diff --git a/drivers/vhost/vhost.h b/drivers/vhost/vhost.h
index c387ee8..a89103c 100644
--- a/drivers/vhost/vhost.h
+++ b/drivers/vhost/vhost.h
@@ -151,6 +151,7 @@ struct vhost_virtqueue {
 	u32 busyloop_timeout;
 	struct page *page_desc;
 	struct vring_desc *desc_vaddr;
+	struct vring_desc descs[64];
 };
 
 struct vhost_msg_node {
@@ -233,7 +234,8 @@ ssize_t vhost_chr_write_iter(struct vhost_dev *dev,
 int vhost_init_device_iotlb(struct vhost_dev *d, bool enabled);
 int vhost_prefetch_desc_indices(struct vhost_virtqueue *vq,
 				struct vring_used_elem *heads,
-				u16 num);
+				struct vring_desc *desc,
+				u16 num, bool *cont);
 
 #define vq_err(vq, fmt, ...) do {                                  \
 		pr_debug(pr_fmt(fmt), ##__VA_ARGS__);       \
