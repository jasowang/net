Bottom: c78e8d322194619f6928c14e259d705800c332c7
Top:    561b0234bc0762f4a62c8b1c6fa76412931ee976
Author: Jason Wang <jasowang@redhat.com>
Date:   2017-03-16 13:28:26 +0800

vhost_net: rx batching

Signed-off-by: Jason Wang <jasowang@redhat.com>


---

diff --git a/drivers/net/tun.c b/drivers/net/tun.c
index f483d4b..1f1624f 100644
--- a/drivers/net/tun.c
+++ b/drivers/net/tun.c
@@ -1498,9 +1498,8 @@ static struct sk_buff *tun_ring_recv(struct tun_file *tfile, int noblock,
 
 static ssize_t tun_do_read(struct tun_struct *tun, struct tun_file *tfile,
 			   struct iov_iter *to,
-			   int noblock)
+			   int noblock, struct sk_buff *skb)
 {
-	struct sk_buff *skb;
 	ssize_t ret;
 	int err;
 
@@ -1509,10 +1508,12 @@ static ssize_t tun_do_read(struct tun_struct *tun, struct tun_file *tfile,
 	if (!iov_iter_count(to))
 		return 0;
 
-	/* Read frames from ring */
-	skb = tun_ring_recv(tfile, noblock, &err);
-	if (!skb)
-		return err;
+	if (!skb) {
+		/* Read frames from ring */
+		skb = tun_ring_recv(tfile, noblock, &err);
+		if (!skb)
+			return err;
+	}
 
 	ret = tun_put_user(tun, tfile, skb, to);
 	if (unlikely(ret < 0))
@@ -1532,7 +1533,7 @@ static ssize_t tun_chr_read_iter(struct kiocb *iocb, struct iov_iter *to)
 
 	if (!tun)
 		return -EBADFD;
-	ret = tun_do_read(tun, tfile, to, file->f_flags & O_NONBLOCK);
+	ret = tun_do_read(tun, tfile, to, file->f_flags & O_NONBLOCK, NULL);
 	ret = min_t(ssize_t, ret, len);
 	if (ret > 0)
 		iocb->ki_pos = ret;
@@ -1634,7 +1635,8 @@ static int tun_recvmsg(struct socket *sock, struct msghdr *m, size_t total_len,
 					 SOL_PACKET, TUN_TX_TIMESTAMP);
 		goto out;
 	}
-	ret = tun_do_read(tun, tfile, &m->msg_iter, flags & MSG_DONTWAIT);
+	ret = tun_do_read(tun, tfile, &m->msg_iter, flags & MSG_DONTWAIT,
+			  m->msg_control);
 	if (ret > (ssize_t)total_len) {
 		m->msg_flags |= MSG_TRUNC;
 		ret = flags & MSG_TRUNC ? ret : total_len;
diff --git a/drivers/vhost/net.c b/drivers/vhost/net.c
index ed8669c..f6caa72 100644
--- a/drivers/vhost/net.c
+++ b/drivers/vhost/net.c
@@ -29,6 +29,8 @@
 #include <linux/if_tap.h>
 #include <linux/if_vlan.h>
 #include <linux/skb_array.h>
+#include <linux/skbuff.h>
+#include <linux/skb_array.h>
 
 #include <net/sock.h>
 
@@ -86,6 +88,7 @@ struct vhost_net_ubuf_ref {
 	struct vhost_virtqueue *vq;
 };
 
+#define VHOST_RX_BATCH 16
 struct vhost_net_virtqueue {
 	struct vhost_virtqueue vq;
 	size_t vhost_hlen;
@@ -100,6 +103,9 @@ struct vhost_net_virtqueue {
 	/* Reference counting for outstanding ubufs.
 	 * Protected by vq mutex. Writers must also take device mutex. */
 	struct vhost_net_ubuf_ref *ubufs;
+	struct sk_buff *skbs[VHOST_RX_BATCH];
+	int nskbs;
+	int skb_index;
 };
 
 struct vhost_net {
@@ -202,6 +208,8 @@ static void vhost_net_vq_reset(struct vhost_net *n)
 		n->vqs[i].ubufs = NULL;
 		n->vqs[i].vhost_hlen = 0;
 		n->vqs[i].sock_hlen = 0;
+		n->vqs[i].nskbs = 0;
+		n->vqs[i].skb_index = 0;
 	}
 
 }
@@ -536,25 +544,40 @@ static int sk_has_rx_data(struct sock *sk)
 	return skb_queue_empty(&sk->sk_receive_queue);
 }
 
-static bool sk_rx_array_has_data(struct sock *sk)
+static bool sk_rx_array_has_data(struct vhost_net_virtqueue *rvq,
+				 struct sock *sk)
 {
 	struct socket *sock = sk->sk_socket;
 	struct skb_array *skb_array = tap_get_skb_array(sock->file);
-
-	if (skb_array)
-		return !__skb_array_empty(skb_array);
-	else
+	struct sk_buff *skb;
+
+	if (skb_array) {
+		if (rvq->skb_index != rvq->nskbs)
+			return true;
+		rvq->skb_index = 0;
+		spin_lock_bh(&skb_array->ring.consumer_lock);
+		while (rvq->nskbs < VHOST_RX_BATCH) {
+			skb = __skb_array_consume(skb_array);
+			if (!skb)
+				break;
+			rvq->skbs[rvq->nskbs++] = skb;
+		}
+		spin_unlock_bh(&skb_array->ring.consumer_lock);
+		return rvq->skb_index != rvq->nskbs;
+	} else
 		return sk_has_rx_data(sk);
 }
 
 static int vhost_net_rx_peek_head_len(struct vhost_net *net,
 				      struct sock *sk)
 {
+	struct vhost_net_virtqueue *rvq = &net->vqs[VHOST_NET_VQ_RX];
 	struct vhost_net_virtqueue *nvq = &net->vqs[VHOST_NET_VQ_TX];
 	struct vhost_virtqueue *vq = &nvq->vq;
 	unsigned long uninitialized_var(endtime);
 	int mergeable = vhost_has_feature(vq, VIRTIO_NET_F_MRG_RXBUF);
-	int len = mergeable ? peek_head_len(sk) : sk_rx_array_has_data(sk);
+	int len = mergeable ? peek_head_len(sk) :
+		  sk_rx_array_has_data(rvq, sk);
 
 	if (!len && vq->busyloop_timeout) {
 		/* Both tx vq and rx socket were polled here */
@@ -575,7 +598,8 @@ static int vhost_net_rx_peek_head_len(struct vhost_net *net,
 			vhost_poll_queue(&vq->poll);
 		mutex_unlock(&vq->mutex);
 
-		len = mergeable ? peek_head_len(sk) : sk_rx_array_has_data(sk);
+		len = mergeable ? peek_head_len(sk) :
+		      sk_rx_array_has_data(rvq, sk);
 	}
 
 	return len;
@@ -718,6 +742,7 @@ static void handle_rx(struct vhost_net *net)
 				vhost_len = vq->heads[0].len;
 				sock_len = vhost_len - vhost_hlen;
 			}
+			msg.msg_control = nvq->skbs[nvq->skb_index++];
 		}
 
 		/* On error, stop handling until the next kick. */
@@ -865,6 +890,8 @@ static int vhost_net_open(struct inode *inode, struct file *f)
 		n->vqs[i].done_idx = 0;
 		n->vqs[i].vhost_hlen = 0;
 		n->vqs[i].sock_hlen = 0;
+		n->vqs[i].nskbs = 0;
+		n->vqs[i].skb_index = 0;
 	}
 	vhost_dev_init(dev, vqs, VHOST_NET_VQ_MAX);
 
diff --git a/include/linux/skb_array.h b/include/linux/skb_array.h
index f4dfade..5252495 100644
--- a/include/linux/skb_array.h
+++ b/include/linux/skb_array.h
@@ -97,6 +97,11 @@ static inline struct sk_buff *skb_array_consume(struct skb_array *a)
 	return ptr_ring_consume(&a->ring);
 }
 
+static inline struct sk_buff *__skb_array_consume(struct skb_array *a)
+{
+	return __ptr_ring_consume(&a->ring);
+}
+
 static inline struct sk_buff *skb_array_consume_irq(struct skb_array *a)
 {
 	return ptr_ring_consume_irq(&a->ring);
