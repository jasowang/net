Bottom: ae8899d46f740a82dc556ef426bc3a456f7686ed
Top:    26cd219a844320c53cd246827e8ee8f18ec70831
Author: Jason Wang <jasowang@redhat.com>
Date:   2016-05-09 14:56:12 +0800

formal patch

Signed-off-by: Jason Wang <jasowang@redhat.com>

---

diff --git a/drivers/net/tun.c b/drivers/net/tun.c
index 8864f2a..8eb9afb 100644
--- a/drivers/net/tun.c
+++ b/drivers/net/tun.c
@@ -527,7 +527,7 @@ static struct tun_struct *tun_enable_queue(struct tun_file *tfile)
 
 static void tun_queue_purge(struct tun_file *tfile)
 {
-//	skb_queue_purge(&tfile->sk.sk_receive_queue);
+	skb_queue_purge(&tfile->sk.sk_receive_queue);
 	spin_lock(&tfile->rlock);
 	while (tfile->tail != tfile->head) {
 		struct sk_buff *skb = tfile->tx_descs[tfile->head].skb;
@@ -836,6 +836,48 @@ static int tun_net_close(struct net_device *dev)
 	return 0;
 }
 
+static bool tun_can_xmit(struct tun_struct *tun, struct tun_file *tfile,
+			 struct sk_buff *skb)
+{
+	if (tun->flags & IFF_TX_RING) {
+		if (((tfile->tail + 1) & TUN_RING_MASK) == tfile->head)
+			return false;
+	} else {
+		if (skb_queue_len(&tfile->socket.sk->sk_receive_queue)
+			          * tun->numqueues >= tun->dev->tx_queue_len)
+			return false;
+	}
+	return true;
+}
+
+static bool tun_xmit_skb(struct tun_struct *tun, struct tun_file *tfile,
+			 struct sk_buff *skb)
+{
+	if (tun->flags & IFF_TX_RING) {
+		unsigned long flags;
+
+		spin_lock_irqsave(&tfile->wlock, flags);
+
+		if (((tfile->tail + 1) & TUN_RING_MASK) == tfile->head) {
+			spin_unlock_irqrestore(&tfile->wlock, flags);
+			goto drop;
+		}
+		tfile->tx_descs[tfile->tail].skb = skb;
+		tfile->tx_descs[tfile->tail].len = skb->len;
+		/* Make sure tail is seen after descriptor */
+		smp_wmb();
+		tfile->tail = (tfile->tail + 1) & TUN_RING_MASK;
+
+		spin_unlock_irqrestore(&tfile->wlock, flags);
+	} else {
+		skb_queue_tail(&tfile->socket.sk->sk_receive_queue, skb);
+	}
+
+	return true;
+drop:
+	return false;
+}
+
 /* Net device start xmit */
 static netdev_tx_t tun_net_xmit(struct sk_buff *skb, struct net_device *dev)
 {
@@ -843,7 +885,6 @@ static netdev_tx_t tun_net_xmit(struct sk_buff *skb, struct net_device *dev)
 	int txq = skb->queue_mapping;
 	struct tun_file *tfile;
 	u32 numqueues = 0;
-	unsigned long flags;
 
 	rcu_read_lock();
 	tfile = rcu_dereference(tun->tfiles[txq]);
@@ -885,11 +926,7 @@ static netdev_tx_t tun_net_xmit(struct sk_buff *skb, struct net_device *dev)
 	    sk_filter(tfile->socket.sk, skb))
 		goto drop;
 
-	/* Limit the number of packets queued by dividing txq length with the
-	 * number of queues.
-	 */
-	if (skb_queue_len(&tfile->socket.sk->sk_receive_queue) * numqueues
-			  >= dev->tx_queue_len)
+	if (!tun_can_xmit(tun, tfile, skb))
 		goto drop;
 
 	if (unlikely(skb_orphan_frags(skb, GFP_ATOMIC)))
@@ -909,18 +946,9 @@ static netdev_tx_t tun_net_xmit(struct sk_buff *skb, struct net_device *dev)
 	nf_reset(skb);
 
 	/* Enqueue packet */
-	//skb_queue_tail(&tfile->socket.sk->sk_receive_queue, skb);
-
-	if (((tfile->tail + 1) & TUN_RING_MASK) == tfile->head)
+	if (!tun_xmit_skb(tun, tfile, skb))
 		goto drop;
 
-	spin_lock_irqsave(&tfile->wlock, flags);
-	tfile->tx_descs[tfile->tail].skb = skb;
-	tfile->tx_descs[tfile->tail].len = skb->len;
-	smp_wmb();
-	tfile->tail = (tfile->tail + 1) & TUN_RING_MASK;
-	spin_unlock_irqrestore(&tfile->wlock, flags);
-
 	/* Notify and wake up reader process */
 	if (tfile->flags & TUN_FASYNC)
 		kill_fasync(&tfile->fasync, SIGIO, POLL_IN);
@@ -1508,12 +1536,40 @@ done:
 	return total;
 }
 
+static struct sk_buff *tun_recv_datagram(struct tun_struct *tun,
+					 struct tun_file *tfile,
+					 int noblock,
+					 int *err)
+{
+	int peeked, off = 0;
+	if (tun->flags & IFF_TX_RING) {
+		struct sk_buff *skb;
+		spin_lock(&tfile->rlock);
+		if (tfile->head == tfile->tail) {
+			spin_unlock(&tfile->rlock);
+			*err = -EAGAIN;
+			return NULL;
+		}
+		skb = tfile->tx_descs[tfile->head].skb;
+		smp_wmb();
+		tfile->head = (tfile->head + 1) & TUN_RING_MASK;
+		spin_unlock(&tfile->rlock);
+		return skb;
+	} else {
+		/* Read frames from queue */
+		return __skb_recv_datagram(tfile->socket.sk,
+					   noblock ? MSG_DONTWAIT : 0,
+					   &peeked, &off, err);
+	}
+}
+
 static ssize_t tun_do_read(struct tun_struct *tun, struct tun_file *tfile,
 			   struct iov_iter *to,
 			   int noblock)
 {
 	struct sk_buff *skb;
 	ssize_t ret;
+	int err;
 
 	tun_debug(KERN_INFO, tun, "tun_do_read\n");
 
@@ -1523,26 +1579,9 @@ static ssize_t tun_do_read(struct tun_struct *tun, struct tun_file *tfile,
 	if (tun->dev->reg_state != NETREG_REGISTERED)
 		return -EIO;
 
-	spin_lock(&tfile->rlock);
-
-	if (tfile->head == tfile->tail) {
-		spin_unlock(&tfile->rlock);
-		return -EAGAIN;
-	}
-
-	skb = tfile->tx_descs[tfile->head].skb;
-	smp_wmb();
-	tfile->head = (tfile->head + 1) & TUN_RING_MASK;
-
-	spin_unlock(&tfile->rlock);
-
-#if 0
-	/* Read frames from queue */
-	skb = __skb_recv_datagram(tfile->socket.sk, noblock ? MSG_DONTWAIT : 0,
-				  &peeked, &off, &err);
+	skb = tun_recv_datagram(tun, tfile, noblock, &err);
 	if (!skb)
 		return err;
-#endif
 
 	ret = tun_put_user(tun, tfile, skb, to);
 	if (unlikely(ret < 0))
@@ -1677,11 +1716,30 @@ static int tun_peek_len(struct socket *sock)
 {
 	struct tun_file *tfile = container_of(sock, struct tun_file, socket);
 	int last_head = READ_ONCE(tfile->head);
+	struct tun_struct *tun = __tun_get(tfile);
+	int ret;
 
-	if (last_head != tfile->tail)
-		return tfile->tx_descs[last_head].len;
-	else
+	if (!tun)
 		return 0;
+
+	if (tun->flags & IFF_TX_RING) {
+		if (last_head != tfile->tail)
+			ret = tfile->tx_descs[last_head].len;
+		else
+			ret = 0;
+	} else {
+		struct sock *sk = sock->sk;
+		struct sk_buff *skb;
+		unsigned long flags;
+
+		spin_lock_irqsave(&sk->sk_receive_queue.lock, flags);
+		skb = skb_peek(&sk->sk_receive_queue);
+		spin_unlock_irqrestore(&sk->sk_receive_queue.lock, flags);
+		ret = skb ? skb->len : 0;
+	}
+
+	tun_put(tun);
+	return ret;
 }
 
 /* Ops structure to mimic raw sockets with tun */
@@ -2115,6 +2173,11 @@ static long __tun_chr_ioctl(struct file *file, unsigned int cmd,
 		break;
 
 	case TUNSETPERSIST:
+		if (tun->flags & IFF_TX_RING) {
+			ret = -EINVAL;
+			break;
+		}
+
 		/* Disable/Enable persist mode. Keep an extra reference to the
 		 * module to prevent the module being unprobed.
 		 */
diff --git a/include/uapi/linux/if_tun.h b/include/uapi/linux/if_tun.h
index 3cb5e1d..39061f1 100644
--- a/include/uapi/linux/if_tun.h
+++ b/include/uapi/linux/if_tun.h
@@ -61,6 +61,7 @@
 #define IFF_TUN		0x0001
 #define IFF_TAP		0x0002
 #define IFF_NO_PI	0x1000
+#define IFF_TX_RING	0x0004
 /* This flag has no real effect */
 #define IFF_ONE_QUEUE	0x2000
 #define IFF_VNET_HDR	0x4000
