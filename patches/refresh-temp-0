Bottom: 341bbfede37c0f5fd3207f80bd5f5bd045dbef21
Top:    c254f8b910282028c7a754aa6e5938952d7c4a9f
Author: Jason Wang <jasowang@redhat.com>
Date:   2018-07-04 17:37:35 +0800

Refresh of tuntap-switch-to-use

---

diff --git a/drivers/net/tun.c b/drivers/net/tun.c
index a192a01..38574cd 100644
--- a/drivers/net/tun.c
+++ b/drivers/net/tun.c
@@ -186,6 +186,7 @@ struct tun_file {
 	struct tun_struct *detached;
 	struct ptr_ring tx_ring;
 	struct xdp_rxq_info xdp_rxq;
+	struct list_head rx_list;
 };
 
 struct tun_flow_entry {
@@ -1562,11 +1563,11 @@ static void tun_rx_batched(struct tun_struct *tun, struct tun_file *tfile,
 			   struct sk_buff *skb, int more)
 {
 	struct sk_buff_head *queue = &tfile->sk.sk_write_queue;
-	struct sk_buff_head process_queue;
+	struct list_head list;
 	u32 rx_batched = tun->rx_batched;
 	bool rcv = false;
 
-	if (!rx_batched || (!more && skb_queue_empty(queue))) {
+	if (!rx_batched || (!more && list_empty(&tfile->rx_list))) {
 		local_bh_disable();
 		netif_receive_skb(skb);
 		local_bh_enable();
@@ -1575,21 +1576,17 @@ static void tun_rx_batched(struct tun_struct *tun, struct tun_file *tfile,
 
 	spin_lock(&queue->lock);
 	if (!more || skb_queue_len(queue) == rx_batched) {
-		__skb_queue_head_init(&process_queue);
-		skb_queue_splice_tail_init(queue, &process_queue);
+		list = tfile->rx_list;
+		INIT_LIST_HEAD(&tfile->rx_list);
 		rcv = true;
 	} else {
-		__skb_queue_tail(queue, skb);
+		list_add_tail(&skb->list, &tfile->rx_list);
 	}
 	spin_unlock(&queue->lock);
 
 	if (rcv) {
-		struct sk_buff *nskb;
-
 		local_bh_disable();
-		while ((nskb = __skb_dequeue(&process_queue)))
-			netif_receive_skb(nskb);
-		netif_receive_skb(skb);
+		netif_receive_skb_list(&list);
 		local_bh_enable();
 	}
 }
@@ -3258,6 +3255,7 @@ static int tun_chr_open(struct inode *inode, struct file * file)
 
 	file->private_data = tfile;
 	INIT_LIST_HEAD(&tfile->next);
+	INIT_LIST_HEAD(&tfile->rx_list);
 
 	sock_set_flag(&tfile->sk, SOCK_ZEROCOPY);
