Bottom: d05239b3803616427bde5025c139757d9e5d34b5
Top:    e285f943bf4db8be466e637d38cf626d28e76ec6
Author: Jason Wang <jasowang@redhat.com>
Date:   2018-04-23 16:57:48 +0800

vhost_net: build skb and XDP buffer on its own

Signed-off-by: Jason Wang <jasowang@redhat.com>


---

diff --git a/drivers/vhost/net.c b/drivers/vhost/net.c
index f1f9b44..be3c1b9 100644
--- a/drivers/vhost/net.c
+++ b/drivers/vhost/net.c
@@ -453,6 +453,80 @@ static bool vhost_exceeds_maxpend(struct vhost_net *net)
 	       min_t(unsigned int, VHOST_MAX_PEND, vq->num >> 2);
 }
 
+#define VHOST_NET_HEADROOM 256
+#define VHOST_NET_RX_PAD (NET_IP_ALIGN + NET_SKB_PAD)
+
+static struct sk_buff *vhost_net_build_pkt(struct vhost_virtqueue *nvq,
+					   struct iov_iter *from,
+					   struct xdp_buff *xdp)
+{
+	struct vhost_virtqueue *vq = &nvq->vq;
+	struct page_frag *alloc_frag = &current->task_frag;
+	struct virtio_net_hdr gso = { 0 };
+	size_t len = iov_iter_count(from);
+	int buflen = SKB_DATA_ALIGN(sizeof(struct skb_shared_info));
+	int pad = VHOST_NET_RX_PAD + VHOST_NET_HEADROOM;
+	void *ret;
+
+	if (len < nvq->sock_hlen)
+		return ERR_PTR(-EFAULT);
+
+	len -= nvq->sock_hlen;
+
+	if (!copy_from_iter_full(&gso, sizeof(gso), from))
+		return ERR_PTR(-EFAULT);
+
+	if ((gso.flags & VIRTIO_NET_HDR_F_NEEDS_CSUM) &&
+	    vhost16_to_cpu(&vq->vq, gso.csum_start) +
+	    vhost16_to_cpu(&vq->vq, gso.csum_offset) + 2 >
+	    vhost16_to_cpu(&vq->vq, gso.hdr_len))
+		gso.hdr_len = cpu_to_vhost16(vq,
+			      vhost16_to_cpu(vq, gso.csum_start) +
+			      vhost16_to_cpu(vq, gso.csum_offset) + 2);
+
+		if (vhost16_to_cpu(vq, gso.hdr_len) > len)
+			return -EINVAL;
+
+	iov_iter_advance(from, sock_hlen - sizeof(gso));
+
+	if (SKB_DATA_ALIGN(len + pad) +
+	    SKB_DATA_ALIGN(sizeof(struct skb_shared_info)) > PAGE_SIZE)
+		return NULL;
+
+	buflen += SKB_DATA_ALIGN(len + pad);
+	alloc_frag->offset = ALIGN((u64)alloc_frag->offset, SMP_CACHE_BYTES);
+	if (unlikely(!skb_page_frag_refill(buflen, alloc_frag, GFP_KERNEL)))
+		return ERR_PTR(-ENOMEM);
+
+	buf = (char *)page_address(alloc_frag->page) + alloc_frag->offset;
+	copied = copy_page_from_iter(alloc_frag->page,
+				     alloc_frag->offset + pad,
+				     len, from);
+	if (copied != len)
+		return ERR_PTR(-EFAULT);
+
+	/* GSO packet, build skb */
+	if (gso.gso_type) {
+		ret = build_skb(buf, buf_len);
+		if (!skb)
+			return ERR_PTR(-ENOMEM);
+		skb_reserve(skb, pad);
+		skb_put(skb, len);
+		get_page(alloc_frag->page);
+		alloc_frag->offset += buflen;
+
+		return ret;
+	}
+
+	xdp->data_hard_start = buf;
+	xdp->data = buf + pad;
+	xdp_set_data_meta_invalid(xdp);
+	xdp.data_end = xdp.data + len;
+	*(int *)xdp.data_hard_start = buflen;
+
+	return NULL;
+}
+
 /* Expects to be always run from workqueue - which acts as
  * read-size critical section for our kind of RCU. */
 static void handle_tx(struct vhost_net *net)
