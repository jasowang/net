Bottom: 170d3ecb9c357d27c1d1930b316ded3d50dbafde
Top:    a270a923d0c6059be4bfff0c13aa536eff471403
Author: Jason Wang <jasowang@redhat.com>
Date:   2018-07-16 10:56:08 +0800

Refresh of debug-map

---

diff --git a/drivers/net/virtio_net.c b/drivers/net/virtio_net.c
index b5c011a..e83ac5a 100644
--- a/drivers/net/virtio_net.c
+++ b/drivers/net/virtio_net.c
@@ -266,6 +266,8 @@ struct virtnet_bpf_bound_prog {
 	const char *state;
 	bool is_loaded;
 	struct list_head l;
+	u32 len;
+	struct bpf_insn insnsi[0];
 };
 
 #define VIRTNET_EA(extack, msg)	NL_SET_ERR_MSG_MOD((extack), msg)
@@ -1593,12 +1595,14 @@ static bool virtnet_send_command(struct virtnet_info *vi, u8 class, u8 cmd,
 	if (unlikely(!virtqueue_kick(vi->cvq)))
 		return vi->ctrl->status == VIRTIO_NET_OK;
 
+	printk("wait for response!\n");
 	/* Spin for a response, the kick causes an ioport write, trapping
 	 * into the hypervisor, so the request should be handled immediately.
 	 */
 	while (!virtqueue_get_buf(vi->cvq, &tmp) &&
 	       !virtqueue_is_broken(vi->cvq))
 		cpu_relax();
+	printk("response get!\n");
 
 	return vi->ctrl->status == VIRTIO_NET_OK;
 }
@@ -2403,14 +2407,18 @@ static int virtnet_bpf_create_prog(struct virtnet_info *vi,
 				   struct bpf_prog *prog)
 {
 	struct virtnet_bpf_bound_prog *state;
+	size_t insn_len = prog->len * sizeof(struct bpf_insn);
 	char name[16];
 
-	state = kzalloc(sizeof(*state), GFP_KERNEL);
+	state = kzalloc(sizeof(*state) + insn_len, GFP_KERNEL);
 	if (!state)
 		return -ENOMEM;
 
+	memcpy(&state->insnsi[0], prog->insnsi, insn_len);
+
 	state->vi = vi;
 	state->prog = prog;
+	state->len = prog->len;
 	state->state = "verify";
 
 	/* Program id is not populated yet when we create the state. */
@@ -2540,6 +2548,7 @@ static int virtnet_xdp_set_prog(struct virtnet_info *vi, struct netdev_bpf *bpf)
 {
 	struct virtio_device *vdev = vi->vdev;
 	struct bpf_prog *prog = bpf->prog;
+	struct virtnet_bpf_bound_prog *bound_prog = prog->aux->offload->dev_priv;
 	struct scatterlist sg;
 	int err, i;
 
@@ -2564,13 +2573,18 @@ static int virtnet_xdp_set_prog(struct virtnet_info *vi, struct netdev_bpf *bpf)
 	printk("prog->len %d total %d\n",
 		prog->len, prog->len * sizeof(prog->insnsi[0]));
 
+	printk("bound_prog->len %d total %d\n",
+		bound_prog->len, bound_prog->len * sizeof(prog->insnsi[0]));
+
 	for (i = 0; i < prog->len; i++)
-		printk("insn %d opcode %x\n", i, prog->insnsi[i].code);
+		printk("insn %d opcode %x\n", i, bound_prog->insnsi[i].code);
 
-	memcpy(vi->ctrl->insns, prog->insnsi,
-	       prog->len * sizeof(prog->insnsi[0]));
-	printk("ctl addr %p prog addr %p\n", &vi->ctrl->hdr, prog->insnsi);
-	sg_init_one(&sg, vi->ctrl->insns, prog->len * sizeof(prog->insnsi[0]));
+	memcpy(vi->ctrl->insns, bound_prog->insnsi,
+		prog->len * sizeof(bound_prog->insnsi[0]));
+	sg_init_one(&sg, vi->ctrl->insns,
+		    bound_prog->len * sizeof(bound_prog->insnsi[0]));
+
+	printk("set offload prog!\n");
 	if (!virtnet_send_command(vi, VIRTIO_NET_CTRL_EBPF,
 				  VIRTIO_NET_CTRL_EBPF_SET_OFFLOAD_PROG,
 				  &sg)) {
@@ -2610,8 +2624,9 @@ static int virtnet_bpf_ctrl_entry_op(struct bpf_offloaded_map *offmap,
 
 	ctrl->cmd = cpu_to_virtio64(vi->vdev, cmd);
 	ctrl->flags = cpu_to_virtio64(vi->vdev, flags);
-	ctrl->map_fd = 0; /* FIXME */
+	ctrl->map_fd = virtnet_map->id;
 
+	printk("entry op send command %d\n", ctrl->cmd);
 	sg_init_one(&sg, &vi->ctrl->ebpf, sizeof(vi->ctrl->ebpf));
 	if (!virtnet_send_command(vi, VIRTIO_NET_CTRL_EBPF_MAP,
 				  VIRTIO_NET_CTRL_EBPF_MAP_CMD,
@@ -2713,13 +2728,14 @@ static int virtnet_bpf_map_alloc(struct virtnet_info *vi,
 
 	virtnet_map->offmap = offmap;
 	virtnet_map->id = ctrl->map_fd;
+
+	printk("success get map id from host %d\n", ctrl->map_fd);
+
 	list_add_tail(&virtnet_map->l, &vi->map_list);
 
 	return 0;
 }
 
-
-
 static int virtnet_bpf(struct net_device *dev, struct netdev_bpf *bpf)
 {
 	struct virtnet_info *vi = netdev_priv(dev);
diff --git a/drivers/virtio/virtio_ring.c b/drivers/virtio/virtio_ring.c
index 074b418..b7d33a7 100644
--- a/drivers/virtio/virtio_ring.c
+++ b/drivers/virtio/virtio_ring.c
@@ -344,7 +344,6 @@ static inline int virtqueue_add(struct virtqueue *_vq,
 			desc[i].flags = cpu_to_virtio16(_vq->vdev, VRING_DESC_F_NEXT);
 			desc[i].addr = cpu_to_virtio64(_vq->vdev, addr);
 			desc[i].len = cpu_to_virtio32(_vq->vdev, sg->length);
-			printk("out desc.addr %llx desc.len %d\n", desc[i].addr, desc[i].len);
 			prev = i;
 			i = virtio16_to_cpu(_vq->vdev, desc[i].next);
 		}
@@ -358,7 +357,6 @@ static inline int virtqueue_add(struct virtqueue *_vq,
 			desc[i].flags = cpu_to_virtio16(_vq->vdev, VRING_DESC_F_NEXT | VRING_DESC_F_WRITE);
 			desc[i].addr = cpu_to_virtio64(_vq->vdev, addr);
 			desc[i].len = cpu_to_virtio32(_vq->vdev, sg->length);
-			printk("in desc.addr %llx desc.len %d\n", desc[i].addr, desc[i].len);
 			prev = i;
 			i = virtio16_to_cpu(_vq->vdev, desc[i].next);
 		}
diff --git a/kernel/bpf/offload.c b/kernel/bpf/offload.c
index ac747d5..7b74b2a 100644
--- a/kernel/bpf/offload.c
+++ b/kernel/bpf/offload.c
@@ -299,9 +299,11 @@ struct bpf_map *bpf_map_offload_map_alloc(union bpf_attr *attr)
 
 	if (!capable(CAP_SYS_ADMIN))
 		return ERR_PTR(-EPERM);
+#if 0
 	if (attr->map_type != BPF_MAP_TYPE_ARRAY &&
 	    attr->map_type != BPF_MAP_TYPE_HASH)
 		return ERR_PTR(-EINVAL);
+#endif
 
 	offmap = kzalloc(sizeof(*offmap), GFP_USER);
 	if (!offmap)
diff --git a/kernel/bpf/syscall.c b/kernel/bpf/syscall.c
index 0f55f79..3e65b34 100644
--- a/kernel/bpf/syscall.c
+++ b/kernel/bpf/syscall.c
@@ -59,6 +59,8 @@ static const struct bpf_map_ops * const bpf_map_types[] = {
 #undef BPF_MAP_TYPE
 };
 
+#define DBG() printk("file %s line %d\n", __FILE__, __LINE__)
+
 /*
  * If we're handed a bigger struct than we know of, ensure all the unknown bits
  * are 0 - i.e. new user-space does not rely on any kernel feature extensions
@@ -436,24 +438,29 @@ static int map_create(union bpf_attr *attr)
 	int f_flags;
 	int err;
 
+	DBG();
 	err = CHECK_ATTR(BPF_MAP_CREATE);
 	if (err)
 		return -EINVAL;
 
+	DBG();
 	f_flags = bpf_get_file_flag(attr->map_flags);
 	if (f_flags < 0)
 		return f_flags;
 
+	DBG();
 	if (numa_node != NUMA_NO_NODE &&
 	    ((unsigned int)numa_node >= nr_node_ids ||
 	     !node_online(numa_node)))
 		return -EINVAL;
 
+	DBG();
 	/* find map type and init map: hashtable vs rbtree vs bloom vs ... */
 	map = find_and_alloc_map(attr);
 	if (IS_ERR(map))
 		return PTR_ERR(map);
 
+	DBG();
 	err = bpf_obj_name_cpy(map->name, attr->map_name);
 	if (err)
 		goto free_map_nouncharge;
@@ -2324,6 +2331,7 @@ SYSCALL_DEFINE3(bpf, int, cmd, union bpf_attr __user *, uattr, unsigned int, siz
 
 	switch (cmd) {
 	case BPF_MAP_CREATE:
+		DBG();
 		err = map_create(&attr);
 		break;
 	case BPF_MAP_LOOKUP_ELEM:
