Bottom: 215f29bb14058afa99213c595556e70146bc456c
Top:    87b9327b95ea1341e6e55f81463ff2a915140a0f
Author: Jason Wang <jasowang@redhat.com>
Date:   2017-03-22 14:59:36 +0800

Refresh of vhost_net-prefetch-desc

---

diff --git a/drivers/vhost/net.c b/drivers/vhost/net.c
index 31199b2..836800a 100644
--- a/drivers/vhost/net.c
+++ b/drivers/vhost/net.c
@@ -675,16 +675,80 @@ static int get_rx_bufs(struct vhost_virtqueue *vq,
 	return r;
 }
 
-static void handle_rx_batched(struct vhost_net *net)
+static int rx_recvmsg(struct vhost_net_virtqueue *nvq, int in,
+		      struct sk_buff *skb)
+{
+	struct vhost_virtqueue *vq = &nvq->vq;
+	size_t vhost_hlen = nvq->vhost_hlen;
+	size_t sock_hlen = nvq->sock_hlen;
+	struct socket *sock = vq->private_data;
+	struct vhost_log *vq_log;
+	struct msghdr msg = {
+		.msg_name = NULL,
+		.msg_namelen = 0,
+		.msg_control = skb,
+		.msg_controllen = 0,
+		.msg_flags = MSG_DONTWAIT,
+	};
+	struct iov_iter fixup;
+	__virtio16 num_buffers;
+
+	/* We don't need to be notified again. */
+	iov_iter_init(&msg.msg_iter, READ, vq->iov, in, vhost_len);
+	fixup = msg.msg_iter;
+	if (unlikely((vhost_hlen))) {
+		/* We will supply the header ourselves
+		 * TODO: support TSO.
+		 */
+		iov_iter_advance(&msg.msg_iter, vhost_hlen);
+	}
+	err = sock->ops->recvmsg(sock, &msg,
+				sock_len, MSG_DONTWAIT | MSG_TRUNC);
+	/* Userspace might have consumed the packet meanwhile:
+	 * it's not supposed to do this usually, but might be hard
+	 * to prevent. Discard data we got (if any) and keep going. */
+	if (unlikely(err != sock_len)) {
+		pr_debug("Discarded rx packet: "
+			" len %d, expected %zd\n", err, sock_len);
+		vhost_discard_vq_desc(vq, 1);
+		return -E2BIG
+	}
+	/* Supply virtio_net_hdr if VHOST_NET_F_VIRTIO_NET_HDR */
+	if (unlikely(vhost_hlen)) {
+		if (copy_to_iter(&hdr, sizeof(hdr),
+					&fixup) != sizeof(hdr)) {
+			vq_err(vq, "Unable to write vnet_hdr "
+				"at addr %p\n", vq->iov->iov_base);
+			return -EFAULT;
+		}
+	} else {
+		/* Header came from socket; we'll need to patch
+		 * ->num_buffers over if VIRTIO_NET_F_MRG_RXBUF
+		 */
+		iov_iter_advance(&fixup, sizeof(hdr));
+	}
+	/* TODO: Should check and handle checksum. */
+
+	num_buffers = cpu_to_vhost16(vq, headcount);
+	if (likely(mergeable) &&
+		copy_to_iter(&num_buffers, sizeof num_buffers,
+			     &fixup) != sizeof num_buffers) {
+		vq_err(vq, "Failed num_buffers write");
+		vhost_discard_vq_desc(vq, headcount);
+		return -EFAULT;
+	}
+}
+
+static void handle_rx_batched(struct vhost_net *net, struct vhost_log *vq_log)
 {
 	struct vhost_net_virtqueue *nvq = &net->vqs[VHOST_NET_VQ_RX];
 	struct vhost_virtqueue *vq = &nvq->vq;
+	unsigned int out, int, log = 0;
 	__virtio16 indices[VHOST_RX_BATCHED];
 	int sock_len, i;
 	int avails, head;
 
 	while ((sock_len = vhost_net_rx_peek_head_len(net, sock->sk))) {
-retry:
 		avails = vhost_prefetch_desc_indices(vq, indices,
 						     nvq->rt - nvq->rh);
 		if (!avail) {
@@ -692,17 +756,35 @@ static void handle_rx_batched(struct vhost_net *net)
 				/* They have slipped one in as we were
 				 * doing that: check again. */
 				vhost_disable_notify(&net->dev, vq);
-				goto retry;
+				continue;
 			}
-			goto out;
+			return;
 		}
 		for (i = 0; i < avails; i++) {
 			int len =__skb_array_len_with_tag(rvq->rxq[rvq->rh + i]);
 			vhost_add_used_elem(vq, indices[i],
 					    cpu_to_vhost32(vq, len), i);
 		}
-		while (nvq->rh != nvq->rt) {
-			
+		for (i = 0; i < avail; i++) {
+			if (nvq->rh == nvq->rt) {
+				printk("wrong!\n");
+			}
+			head = vhost_get_vq_desc2(vq, vq->iov,
+						  ARRAY_SIZE(vq->iov),
+						  &out, &in, vq_log,
+						  &log, indices[i]);
+			if (unlikely(head <= 0 || head == vq->num))
+				return;
+			if (rx_recvmsg(nvq, in, nvq->rxq[nvq->rh++]))
+				return;
+
+			vhost_update_used_idx(vq, 1);
+			vhost_signal(&net->dev, vq);
+
+			/* FIXME: count bytes */
+			if (unlikely(vq_log))
+				vhost_log_write(vq, vq_log, log, vhost_len);
+		}
 	}
 }
 
@@ -752,6 +834,12 @@ static void handle_rx(struct vhost_net *net)
 		vq->log : NULL;
 	mergeable = vhost_has_feature(vq, VIRTIO_NET_F_MRG_RXBUF);
 
+	if (!mergeable) {
+		handle_rx_batched(net, vq_log);
+		vhost_net_enable_vq(net, vq);
+		goto out;
+	}
+
 	while ((sock_len = vhost_net_rx_peek_head_len(net, sock->sk))) {
 		sock_len += sock_hlen;
 		vhost_len = sock_len + vhost_hlen;
