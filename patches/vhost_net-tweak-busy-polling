Bottom: 85ee0b6d1d77a6f10e76d4279e969a719b3ea428
Top:    347b4aa690ad566460537604fecf7b7e643a4ab2
Author: Jason Wang <jasowang@redhat.com>
Date:   2017-09-14 17:09:09 +0800

vhost_net: tweak busy polling loop logic

Signed-off-by: Jason Wang <jasowang@redhat.com>


---

diff --git a/drivers/vhost/net.c b/drivers/vhost/net.c
index b2509ab..542f06a 100644
--- a/drivers/vhost/net.c
+++ b/drivers/vhost/net.c
@@ -110,6 +110,8 @@ struct vhost_net_virtqueue {
 	struct vhost_net_ubuf_ref *ubufs;
 	struct skb_array *rx_array;
 	struct vhost_net_buf rxq;
+	u64 sleep;
+	u64 wakeup;
 };
 
 struct vhost_net {
@@ -406,10 +408,12 @@ static int vhost_net_tx_get_vq_desc(struct vhost_net *net,
 	if (r == vq->num && vq->busyloop_timeout) {
 		preempt_disable();
 		endtime = local_clock() + vq->busyloop_timeout;
-		while (vhost_can_busy_poll(vq->dev, endtime) &&
-		       vhost_vq_avail_empty(vq->dev, vq) &&
-		       !vhost_has_work(&net->dev))
+		do {
+			if (!vhost_vq_avail_empty(vq->dev, vq) ||
+			    vhost_has_work(&net->dev))
+				break;
 			cpu_relax();
+		} while (vhost_can_busy_poll(vq->dev, endtime));
 		preempt_enable();
 		r = vhost_get_vq_desc(vq, vq->iov, ARRAY_SIZE(vq->iov),
 				      out_num, in_num, NULL, NULL);
@@ -485,6 +489,7 @@ static void handle_tx(struct vhost_net *net)
 				vhost_disable_notify(&net->dev, vq);
 				continue;
 			}
+			nvq->sleep = ktime_get_ns();
 			break;
 		}
 		if (in) {
@@ -599,6 +604,25 @@ static int sk_has_rx_data(struct sock *sk)
 	return skb_queue_empty(&sk->sk_receive_queue);
 }
 
+static vhost_net_adjust_poll_ns(struct vhost_net_virtqueue *vq, bool has_buffer)
+{
+	if (!vq->busyloop_timeout)
+		return;
+
+	if (has_buffer) {
+		u64 gap = ktime_get_ns() - vq->last_sleep;
+		if (gap < vq->curr_busy_loop_timeout)
+			return;
+		if (gap > vq->busyloop_timeout)
+			vq->curr_busy_loop_timeout /= 2;
+		else if (gap > vq->curr_busyloop_timeout) {
+			vq->curr_busyloop_timeout *= 2;
+			if (vq->curr_busy_loop_timeout > vq->busyloop_timeout)
+				vq->curr_busyloop_timeout = vq->busyloop_timeout;
+		}
+	}
+}
+
 static int vhost_net_rx_peek_head_len(struct vhost_net *net, struct sock *sk)
 {
 	struct vhost_net_virtqueue *rvq = &net->vqs[VHOST_NET_VQ_RX];
@@ -615,11 +639,13 @@ static int vhost_net_rx_peek_head_len(struct vhost_net *net, struct sock *sk)
 		preempt_disable();
 		endtime = local_clock() + vq->busyloop_timeout;
 
-		while (vhost_can_busy_poll(&net->dev, endtime) &&
-		       !sk_has_rx_data(sk) &&
-		       vhost_vq_avail_empty(&net->dev, vq) &&
-		       !vhost_has_work(&net->dev))
+		do {
+			if (sk_has_rx_data(sk) ||
+			    !vhost_vq_avail_empty(&net->dev, vq) ||
+			    vhost_has_work(&net->dev))
+				break;
 			cpu_relax();
+		} while (vhost_can_busy_poll(&net->dev, endtime));
 
 		preempt_enable();
 
@@ -635,6 +661,22 @@ static int vhost_net_rx_peek_head_len(struct vhost_net *net, struct sock *sk)
 		len = peek_head_len(rvq, sk);
 	}
 
+	if (vq->busyloop_timeout) {
+		if (len) {
+			u64 gap = ktime_get_ns() - nvq->sleep;
+			if (gap < vq->curr_busyloop_timeout)
+				;
+			else if (gap > vq->busyloop_timeout)
+				/* shirnk */;
+			else if (gap < vq->busyloop_timeout &&
+				gap > vq->curr_busyloop_tiemout) {
+				/* grow */;
+			}
+		}
+		else
+			nvq->sleep = ktime_get_ns();
+	}
+
 	return len;
 }
