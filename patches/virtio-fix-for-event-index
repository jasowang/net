Bottom: 9fd287607b74155a2e66ec1a8f734d11d5999418
Top:    acc85403600456599aa0bed3f04d8c7dd155621f
Author: Jason Wang <jasowang@redhat.com>
Date:   2018-05-15 10:47:39 +0800

virtio: fix for event index

Signed-off-by: Jason Wang <jasowang@redhat.com>


---

diff --git a/drivers/virtio/virtio_ring.c b/drivers/virtio/virtio_ring.c
index d543404..77369e3 100644
--- a/drivers/virtio/virtio_ring.c
+++ b/drivers/virtio/virtio_ring.c
@@ -843,6 +843,8 @@ static inline int virtqueue_add_packed(struct virtqueue *_vq,
 		desc = NULL;
 		WARN_ON_ONCE(total_sg > vq->vring_packed.num && !vq->indirect);
 	}
+//	printk("vq %d head %u total_sgs %u wrap_counter %u\n",
+//		_vq->index, head, total_sg, wrap_counter);
 
 	if (desc) {
 		/* Use a single buffer which doesn't continue */
@@ -893,6 +895,8 @@ static inline int virtqueue_add_packed(struct virtqueue *_vq,
 			if (!indirect && i >= vq->vring_packed.num) {
 				i = 0;
 				vq->wrap_counter ^= 1;
+//				printk("vq %d wrap flip to %d nonindirect\n",
+//					_vq->index, vq->wrap_counter);
 			}
 		}
 	}
@@ -935,6 +939,8 @@ static inline int virtqueue_add_packed(struct virtqueue *_vq,
 		if (n >= vq->vring_packed.num) {
 			n = 0;
 			vq->wrap_counter ^= 1;
+//			printk("vq %d wrap counter flip %d\n",
+//				_vq->index, vq->wrap_counter);
 		}
 		vq->next_avail_idx = n;
 	} else
@@ -982,6 +988,24 @@ static inline int virtqueue_add_packed(struct virtqueue *_vq,
 	return -EIO;
 }
 
+static bool vring_packed_need_event(struct vring_virtqueue *vq,
+				    __u16 off_wrap, __u16 new,
+				    __u16 old)
+{
+    bool wrap = vq->wrap_counter;
+    int off = off_wrap & ~(1 << 15);
+
+    if (new < old) {
+	    new += vq->vring_packed.num;
+	    wrap ^= 1;
+    }
+
+    if (wrap != off_wrap >> 15)
+	    off += vq->vring_packed.num;
+
+    return vring_need_event(off, new, old);
+}
+
 static bool virtqueue_kick_prepare_packed(struct virtqueue *_vq)
 {
 	struct vring_virtqueue *vq = to_vvq(_vq);
@@ -1010,10 +1034,16 @@ static bool virtqueue_kick_prepare_packed(struct virtqueue *_vq)
 	vq->last_add_time_valid = false;
 #endif
 
-	if (flags == VRING_EVENT_F_DESC)
-		needs_kick = vring_need_event(off_wrap & ~(1<<15), new, old);
-	else
+	if (flags == VRING_EVENT_F_DESC) {
+		needs_kick = vring_packed_need_event(vq, off_wrap,
+						     new, old);
+//		printk("vq %d old %d new %d event %d wrap %d kick %d\n",
+//			_vq->index, old, new, off_wrap & ~(1 << 15),
+//			off_wrap >> 15, needs_kick);
+	} else {
 		needs_kick = (flags != VRING_EVENT_F_DISABLE);
+//		printk("vq %d needs_kick %d\n", _vq->index, needs_kick);
+	}
 	END_USE(vq);
 	return needs_kick;
 }
@@ -1122,6 +1152,8 @@ static void *virtqueue_get_buf_ctx_packed(struct virtqueue *_vq,
 	vq->last_used_idx += vq->desc_state[i].num;
 	if (vq->last_used_idx >= vq->vring_packed.num)
 		vq->last_used_idx -= vq->vring_packed.num;
+//	printk("vq %d last_used_idx to %u\n",
+//		_vq->index, vq->last_used_idx);
 
 	/* If we expect an interrupt for the next entry, tell host
 	 * by writing event index and flush out the write before
@@ -1145,6 +1177,7 @@ static void virtqueue_disable_cb_packed(struct virtqueue *_vq)
 	struct vring_virtqueue *vq = to_vvq(_vq);
 
 	if (vq->event_flags_shadow != VRING_EVENT_F_DISABLE) {
+//		printk("vq %d set to disable\n", _vq->index);
 		vq->event_flags_shadow = VRING_EVENT_F_DISABLE;
 		vq->vring_packed.driver->flags = cpu_to_virtio16(_vq->vdev,
 							vq->event_flags_shadow);
@@ -1154,6 +1187,7 @@ static void virtqueue_disable_cb_packed(struct virtqueue *_vq)
 static unsigned virtqueue_enable_cb_prepare_packed(struct virtqueue *_vq)
 {
 	struct vring_virtqueue *vq = to_vvq(_vq);
+	bool wrap_counter = vq->wrap_counter;
 
 	START_USE(vq);
 
@@ -1163,13 +1197,25 @@ static unsigned virtqueue_enable_cb_prepare_packed(struct virtqueue *_vq)
 	 * either clear the flags bit or point the event index at the next
 	 * entry. Always update the event index to keep code simple. */
 
+#if 0
+	if (vq->next_avail_idx <= vq->last_used_idx)
+		wrap_counter ^= 1;
+
 	vq->vring_packed.driver->off_wrap = cpu_to_virtio16(_vq->vdev,
-			vq->last_used_idx | (vq->wrap_counter << 15));
+			vq->last_used_idx | (wrap_counter << 15));
+#endif
 
 	if (vq->event_flags_shadow == VRING_EVENT_F_DISABLE) {
+#if 0
+		if (vq->event)
+			printk("vq %d to DESC off_wrap %u last %u wrap %u\n",
+				_vq->index, vq->vring_packed.driver->off_wrap,
+				vq->last_used_idx, vq->wrap_counter);
+		else
+			printk("vq %d to enable\n", _vq->index);
+#endif
 		virtio_wmb(vq->weak_barriers);
-		vq->event_flags_shadow = vq->event ? VRING_EVENT_F_DESC :
-						     VRING_EVENT_F_ENABLE;
+		vq->event_flags_shadow = VRING_EVENT_F_ENABLE;
 		vq->vring_packed.driver->flags = cpu_to_virtio16(_vq->vdev,
 							vq->event_flags_shadow);
 	}
@@ -1196,6 +1242,7 @@ static bool virtqueue_enable_cb_delayed_packed(struct virtqueue *_vq)
 {
 	struct vring_virtqueue *vq = to_vvq(_vq);
 	u16 bufs, used_idx, wrap_counter;
+	u16 next_avail_idx = (u16)vq->next_avail_idx;
 
 	START_USE(vq);
 
@@ -1206,20 +1253,57 @@ static bool virtqueue_enable_cb_delayed_packed(struct virtqueue *_vq)
 	 * entry. Always update the event index to keep code simple. */
 
 	/* TODO: tune this threshold */
-	bufs = (u16)(vq->next_avail_idx - vq->last_used_idx) * 3 / 4;
+	if (next_avail_idx < vq->last_used_idx)
+		next_avail_idx += vq->vring_packed.num;
+	bufs = (u16)(next_avail_idx - vq->last_used_idx) * 3 / 4;
 
 	used_idx = vq->last_used_idx + bufs;
 	wrap_counter = vq->wrap_counter;
 
+	/* +bufs not wrap but next-avail wrap */
 	if (used_idx >= vq->vring_packed.num) {
+		/* Case A
+		 * B              C              A
+		 * |\             |\             |\
+		 * used_idx       next_avail     last_used_idx
+		 */
 		used_idx -= vq->vring_packed.num;
+//		wrap_counter ^= 1;
+#if 0
+		printk("vq %d last %u bufs %u event %u used_idx wrap\n",
+			_vq->index, vq->last_used_idx, bufs, used_idx);
+#endif
+	} else if (vq->next_avail_idx < used_idx) {
+		/* Case B
+		 * C              A               B
+		 * |\             |\              |\
+		 * next_avail     last_used_idx   used_idx
+		 */
 		wrap_counter ^= 1;
+#if 0
+		printk("vq %d last %u bufs %u event %u wrap flip from %d to %dwrap2\n",
+			_vq->index, vq->last_used_idx, bufs, used_idx,
+			vq->wrap_counter, wrap_counter);
+#endif
 	}
-
+	#if 0
+	else
+		printk("vq %d last %u bufs %u event %u wrap %d delayed\n",
+			_vq->index, vq->last_used_idx, bufs, used_idx,
+			wrap_counter);
+	#endif
 	vq->vring_packed.driver->off_wrap = cpu_to_virtio16(_vq->vdev,
 			used_idx | (wrap_counter << 15));
 
 	if (vq->event_flags_shadow == VRING_EVENT_F_DISABLE) {
+#if 0
+		if (vq->event)
+			printk("vq %d set to desc %u\n",
+				_vq->index,
+				vq->vring_packed.driver->off_wrap);
+		else
+			printk("vq %d set to enable!\n", _vq->index);
+#endif
 		virtio_wmb(vq->weak_barriers);
 		vq->event_flags_shadow = vq->event ? VRING_EVENT_F_DESC :
 						     VRING_EVENT_F_ENABLE;
@@ -1658,6 +1742,7 @@ struct virtqueue *__vring_new_virtqueue(unsigned int index,
 	vq->indirect = virtio_has_feature(vdev, VIRTIO_RING_F_INDIRECT_DESC) &&
 		!context;
 	vq->event = virtio_has_feature(vdev, VIRTIO_RING_F_EVENT_IDX);
+//	printk("vq->event is %d\n", vq->event);
 
 	if (vq->packed) {
 		vq->vring_packed = vring.vring_packed;
@@ -1864,10 +1949,8 @@ void vring_transport_features(struct virtio_device *vdev)
 		switch (i) {
 		case VIRTIO_RING_F_INDIRECT_DESC:
 			break;
-#if 0
 		case VIRTIO_RING_F_EVENT_IDX:
 			break;
-#endif
 		case VIRTIO_F_VERSION_1:
 			break;
 		case VIRTIO_F_IOMMU_PLATFORM:
