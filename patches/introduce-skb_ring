Bottom: 579b56b3b42598c5db664ef276979ce37b7c6416
Top:    5bd81bc351caaeb882c5f12d74ea1de314ee315f
Author: Jason Wang <jasowang@redhat.com>
Date:   2016-05-17 14:20:09 +0800

Introduce skb_ring

Signed-off-by: Jason Wang <jasowang@redhat.com>


---

diff --git a/include/linux/skb_ring.h b/include/linux/skb_ring.h
new file mode 100644
index 0000000..9666451
--- /dev/null
+++ b/include/linux/skb_ring.h
@@ -0,0 +1,64 @@
+/*
+ *	skb ring implemented with circular buffer.
+ *
+ *	This program is free software; you can redistribute it and/or
+ *	modify it under the terms of the GNU General Public License
+ *	as published by the Free Software Foundation; either version
+ *	2 of the License, or (at your option) any later version.
+ */
+
+#ifndef _LINUX_SKB_RING_H
+#define _LINUX_SKB_RING_H
+
+#include <asm/barrier.h>
+#include <linux/spinlock.h>
+#include <linux/circ_buf.h>
+#include <linux/skbuff.h>
+
+struct skb_desc {
+	struct sk_buff *skb;
+	int len; /* Cached skb len for peeking */
+};
+
+struct skb_ring {
+	/* reader lock */
+	spinlock_t rlock;
+	unsigned long tail;
+	unsigned long size;
+	struct skb_desc *descs;
+	unsigned long head;
+        /* writer lock */;
+	spinlock_t wlock;
+};
+
+int skb_ring_init(struct skb_ring *ring, unsigned long size);
+void skb_ring_purge(struct skb_ring *ring);
+int skb_ring_queue(struct skb_ring *ring, struct sk_buff *skb);
+struct sk_buff *skb_ring_dequeue(struct skb_ring *ring);
+
+int skb_ring_empty(struct skb_ring *ring)
+{
+	return ACCESS_ONCE(ring->head) == ACCESS_ONCE(ring->tail);
+}
+
+int skb_ring_peek(struct skb_ring *ring)
+{
+	unsigned long head = smp_load_acquire(&ring->head);
+	unsigned long tail = ACCESS_ONCE(ring->tail);
+	int ret = 0;
+
+	if (CIRC_CNT(head, tail, ring->size) >= 1)
+		ret = ring->descs[tail].len;
+
+	return ret;
+}
+
+int skb_ring_queue_len(struct skb_ring *ring)
+{
+	unsigned long head = ACCESS_ONCE(ring->head);
+	unsigned long tail = ACCESS_ONCE(ring->tail);
+
+	return CIRC_CNT(head, tail, ring->size);
+}
+
+#endif /* _LINUX_SKB_RING_H */
diff --git a/net/core/Makefile b/net/core/Makefile
index d6508c2..79f4936 100644
--- a/net/core/Makefile
+++ b/net/core/Makefile
@@ -3,7 +3,8 @@
 #
 
 obj-y := sock.o request_sock.o skbuff.o datagram.o stream.o scm.o \
-	 gen_stats.o gen_estimator.o net_namespace.o secure_seq.o flow_dissector.o
+	 gen_stats.o gen_estimator.o net_namespace.o secure_seq.o \
+	 flow_dissector.o skb_ring.o
 
 obj-$(CONFIG_SYSCTL) += sysctl_net_core.o
 
diff --git a/net/core/skb_ring.c b/net/core/skb_ring.c
new file mode 100644
index 0000000..b4f2ec1
--- /dev/null
+++ b/net/core/skb_ring.c
@@ -0,0 +1,103 @@
+/*
+ */
+
+#include <linux/skb_ring.h>
+#include <linux/if_vlan.h>
+
+int skb_ring_init(struct skb_ring *ring, unsigned long size)
+{
+	spin_lock_init(&ring->rlock);
+	spin_lock_init(&ring->wlock);
+
+	ring->head = 0;
+	ring->tail = 0;
+
+	ring->descs = kmalloc(size * sizeof *ring->descs, GFP_ATOMIC);
+	if (!ring->descs)
+		return -ENOMEM;
+
+	ring->size = size;
+	/* FIXEME: check power of 2 */
+
+	return 0;
+}
+EXPORT_SYMBOL(skb_ring_init);
+
+void skb_ring_purge(struct skb_ring *ring)
+{
+	unsigned long head, tail;
+
+	spin_lock_bh(&ring->rlock);
+	spin_lock(&ring->wlock);
+
+	head = smp_load_acquire(&ring->head);
+	tail = ring->tail;
+
+	while (CIRC_CNT(head, tail, ring->size) >= 1) {
+		struct skb_desc *desc = &ring->descs[tail];
+		struct sk_buff *skb = desc->skb;
+		kfree_skb(skb);
+		/* read descriptor before incrementing tail. */
+		smp_store_release(&ring->tail, (tail + 1) & (ring->size - 1));
+	}
+
+	spin_unlock(&ring->wlock);
+	spin_unlock_bh(&ring->rlock);
+}
+EXPORT_SYMBOL(skb_ring_purge);
+
+int skb_ring_queue(struct skb_ring *ring, struct sk_buff *skb)
+{
+	unsigned long head, tail;
+	int ret = 0;
+
+	spin_lock(&ring->wlock);
+
+	tail = smp_load_acquire(&ring->tail);
+	head = ring->head;
+
+	if (CIRC_SPACE(head, tail, ring->size) >= 1) {
+		struct skb_desc *desc = &ring->descs[head];
+
+		desc->skb = skb;
+		desc->len = skb->len;
+		if (skb_vlan_tag_present(skb))
+			desc->len += VLAN_HLEN;
+
+		/* produce descriptor before incrementing head. */
+		smp_store_release(&ring->head, (head + 1) & (ring->size - 1));
+	} else {
+		ret = -EFAULT;
+	}
+
+	spin_unlock(&ring->wlock);
+
+	return ret;
+}
+EXPORT_SYMBOL(skb_ring_queue);
+
+
+struct sk_buff *skb_ring_dequeue(struct skb_ring *ring)
+{
+	unsigned long head, tail;
+	struct sk_buff *skb = NULL;
+	struct skb_desc *desc;
+
+	spin_lock(&ring->rlock);
+	/* Read index before reading contents at that index. */
+	head = smp_load_acquire(&ring->head);
+	tail = ring->tail;
+
+	if (CIRC_CNT(head, tail, ring->size) >= 1) {
+		desc = &ring->descs[tail];
+		skb = desc->skb;
+		/* read descriptor before incrementing tail. */
+		smp_store_release(&ring->tail, (tail + 1) & (ring->size - 1));
+	}
+
+	spin_unlock(&ring->rlock);
+
+	return skb;
+}
+EXPORT_SYMBOL(skb_ring_dequeue);
+
